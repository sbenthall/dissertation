\documentclass[../thesis.tex]{subfiles}
\begin{document}


In this chapter, I build on the prior sections to
develop a general, formal model of economic information
flow.
This builds on prior work identifying the gaps in
social theoretical understanding of privacy (Chapter 1)
and advancing a formal definition of information flow
compatible with concepts of security and privacy
in computer science (Chapter 2).
I argue that this model is well suited to capturing
the economic impact of information flows through
mechanism design, which can inform both regulation
and privacy by design.

Section \ref{sec:limitations} considers the social
theory of privacy and notes, based on prior work
in Chapter 1 of this dissertation, that cross-context
information flows remain an unresolved theoretical problem
in privacy.
When societal expectations are organized according
the boundaries of social contexts, they cannot easily
anticipate flows that violate those contexts.
In particular, the kinds of information flows in
technical infrastructure and their impact on society
are difficult to conceptualize and therefore
difficult to regulate socially.

Section \ref{sec:law} outlines the legal frameworks
for data protection.
These do offer rationales for preventing cross-context
information flow in particular contexts, such as
health and legal advice, through confidentiality.
These sectoral privacy laws have not prevented
cross-context flows that fall through the gaps
of the law, such as those facilitated by data brokers.
These flows are driven by actors who, unregulated
by the law of society or the law of the state,
are beholden instead by the law of the market.

Section \ref{sec:economics} addresses the existing
economic of privacy and information.
This literature is also organized into analysis
of single economic contexts.
I argue that this is due to a lack of formal modeling
tools for addressing the complex reality of economic
information flow.
Drawing on the formal model of information flow in
Chapter 2 based on Dretske, Pearl, and Nissenbaum,
and multi-agent influence models \cite{koller2003multi},
I develop a framework for mechanism design of games
involving information flows.

Section \ref{sec:single-context} uses the framework
developed in Section \ref{sec:economics} to economic
games of information flow.
This section includes models of: a principal hiring
and agent of uncertain quality; price differentiation
based on personal information; and the provision
of expert advice to a client.
These models demonstrate the expressivity of the
modeling framework.

Section \ref{sec:cross-context} builds on the prior
sections to model a case of cross-context information
flow and its social effects.
The model shows how one firm purchasing an information
flow from another firm can have a negative impact
on consumers who are otherwise not involved in that
transaction.
This shows that the cross-context information flows
can have market externalities, suggesting that
the economy of information flow is prone to market failure.

Section \ref{sec:discussion} concludes the chapter
with a discussion of broader implications and future
work.

\section{The limitiations of contextualized privacy}
\label{sec:limitations}

Privacy is a many-meaninged term
difficult \cite{solove2005taxonomy} to concisely define.
\cite{mulligan2016privacy} argues that privacy is an
essentially pluralistic and contestable
concept that should be defined at the 'retail' rather
than ‘wholesale’ level.
We will call a theory of privacy that maintains
that the term has many distinct and perhaps irreconciliable
meanings a \emph{particularist} account.

The field of contextual integrity \cite{nissenbaum09book}
accounts for variety of meanings of the term by
(1) defining privacy
as \emph{appropriate information flow} and
(2) noting
that what is ``appropriate'' depends on socially situated
expectations or \emph{norms}, that are indexed to social
contexts.
According to this theory, privacy refers to these
social expectations that vary from context
to context.
This theory of privacy both stands up to empirical tests
\cite{martin2016measuring} and has been useful in
privacy engineering (e.g. \cite{shvartzshnaider2016learning},
\cite{benthall2017contextual}).
We will refer to this kind of theory, in which
privacy has a single meaning that is parameterized
by social context a \emph{contextualized} account.

Both particularist and contextualist accounts have trouble addressing legal,
ethical, and technical privacy challenges arising from
social platforms, technologies
that mediate multiple different contexts.
\cite{benthall2017contextual}.
The commonly felt awkwardness of social media due to
the unexpected participation of different audiences
known as \emph{context collapse}
\cite{marwick2011tweet} \cite{davis2014context}
is a symptom of the more general problem
that the digital infrastructure mediating so many
of our social and commercial interactions
is often indifferent to our contextualized social
expectations because it is not ``in'' any one
social context.
In many cases technology makes our \emph{situation}
much more complex and interconnected in ways that
go beyond any social expectations of our social
\emph{spheres}.

Contextual Integrity is socially meaningful and
psychologically compelling.
For most people, our ubiquitous and complex
technical infrastructure, in actuality, is neither.
It is perhaps for precisely this reason that social
norms are not enough to regulate privacy in our
technical infrastructure.

Beyond society's expecations of privacy, there
are also legal limits to the collection and use
of personal data.





\section{Information in the Law}
\label{sec:law}

This section will briefly survey relevant
legal positions on information and data protection.

\subsection{Information as property}

There is a sense of the word ``information'' that
corresponds to physical records--papers on file,
patterns recorded electrically in databases.
This sense of information as a \emph{thing}
\citep{buckland1991information}
perhaps encourages
privacy solutions that frame personal information as a
good that could be protected by property rights and
thereby allocated more efficiently 
\citep{murphy1995property}.
Private property rights create a legal relationship between
a person and a thing that generally transcends
social spheres; robbery of private property is illegal
in almost all social contexts.

The closest existing legal framework for property rights
in information are intellectual property rights laws.
However, intellectual property rights such as those
for copyright, patents, and trade secrets are motivated
by the economic incentivization of innovation, not
by privacy.
They are not designed to protect ownership of data
in general.
For example, copyright specifically does
not pertain to mere data or the organization
of facts. \footnote{Feist v. Rural, 499 U.S. 340 (1991)}
So a data subject does not by default own facts
about themselves.
Databases may be protected as a compilation if
the selection of the data constitute individual,
creative expression.

\citet{samuelson2000privacy} argues that intellectual
property law is a poor fit for protecting privacy because
property rights are alienable whereas privacy interests
are not.
In other words, when party A sells property to party B,
it is generally with no restrictions on whether and how
party B sells that property to party C.
With personal data, individuals commonly have an interest
in sharing their information with one party with the
specific expectation that it is not resold or reused
for an unknown purpose.

Despite the appeal of metaphors that consider data
to be a kind of commodifiable good, like oil 
\citep{hirsch2013glass},
data's real properties and the interest people
have in their personal data defies these metaphors.
Data in general presents a conceptually more
difficult case than the kinds of intellectual
goods considered in intellectual property law.
I will make the case that this is due to data's
ontological slipperiness, a slipperiness that
demands a new method of economic reasoning.

\subsection{Confidentiality and sectoral privacy law}
\label{sec:confidentiality}

United States law has many provisions for the
confidentialiality of personal information gathered
in specific professional contexts.
For example, HIPAA has special provisions for
psychotherapy notes that do not apply to personal health
information more generally.
Attorney-client privilege, which protects personal information
disclosed to ones lawyer, is another example of strongly
protected confidentiality \cite{hazard1978historical} 
\cite{allen1990positive} \cite{richards2007privacy}.
Confidentiality in these domains is meant to ensure
that the protected client can freely divulge personal
information to the service provider without concern
that their information may be used in a secondary way
that harms them.
This is necessary for the effective execution of
these services.
It is notable that in all these cases of expert services,
data protection is mandated by law, not left for market
selection or self-regulation.

These confidentiality cases are perhaps the clearest
cut examples of contextual privacy.
These are examples of \emph{sectoral} privacy laws,
meaning laws that apply only to a single business sector.
This indexes them into a particular social context, the
one defined by that sector's activity.
In the language of Contextual Integrity,
it is clear to which abstract social \emph{sphere}
each law applies.
Notably, these laws generally do not apply to
data collection performed by online services.

Furthermore, confidentiality is a restriction on
information flow.
Restrictions on information flow, when observed,
prevent the collapse of otherwise separate
social \emph{situations} in a more complex and
perhaps conflicted one.
Contextual integrity is specific about
how information norms need not be restrictive,
and sectoral privacy laws indeed do recognize
cases where some kind of information flow
is mandatory (for example, when a hospital
must comply with law enforcement).
But it may be that throttling
information flow between situations that
keeps sphere or sector based information flow
rules enforceable.

\cite{horvitz2015data}

\subsection{Notice and consent}

On-line services that do
not fall under the rubric of any sectoral privacy
laws are regulated in the United States by the
Federal Trade Commission (FTC).
The FTC has encouraged a self-regulatory regime
of ``notice and consent'' whereby on-line services
must transparently describe how they will use
personal data and get consent before collecting it.
The company must abide by the terms of the notice,
even in the case of a corporate merger \cite{hine_2015},
or risk being in violation of the FTC Act Section 5
prohibitions against unfair or deceptive practices. 

The effectiveness of the notice and consent framework
has been widely panned \cite{barocas2009notice}
\cite{reidenberg2015privacy}, as empirically users do
not read legal notices, which are often written in
dense and complex legal and technical language.
This complex language may indeed reflect the complexity
with which collected personal data may be used
\cite{schaub2015design} in practice.
Nevertheless, the scholarly consensus is that
the notice and consent framework does little to
protect privacy in practice

\subsection{GDPR and purpose-binding}
\label{sec:GDPR}

The European Union's General Data Protection Regulation,
which at the time of this writing has not yet gone into
effect, promises to set a significant new standard for
data protection in on-line services.
While it protects only EU citizens, its extraterritorial
enforcement means that many companies that are not based in
the EU must still take significant steps to be compliant
or risk facing heavy fines.

A notable feature of the GDPR is its use of ``purpose binding''
\cite{hildebrandt2013slaves} \cite{herrmann2016privacy}:
data subjects must consent to particular purposes of use
by data processors before the data may be collected.
Exceptions to this rule are also framed in terms of purposes
(such as the purpose to protect the ``vital interests''
of the data subject).
Purpose binding is combined with \emph{data minimization},
the requirement
that data may not be held or processed in excess of what
is needed for the original purposes of collection.

The efficacy of this regulation is still untested.
However, it compares favorably with existing U.S. law.
Narrowing the complexity of notices to be about particular
purposes may be an improvement over the
more complex legal and technical conditions in onotices
typical under the FTC's notice and comment framework.
While some U.S. sectoral privacy policies include
purpose restrictions on information use
\cite{tschantz2012formalizing}, the fact that
the GDPR is an omnibus law means that its purpose
restrictions apply even to those businesses that
fall through the gaps of sectoral regulation.
Truly, the GDPR formalizes new privacy \emph{rights},
which are akin to but unlike other rights like
property rights.


- purpose binding isn't new. It's in the directive; it's in FIPS.

- new obligations: data minimization (see \cite{gurses2011engineering})

- new obligation: privacy by design (see \cite{danezis2015privacy})

\section{Economics and mechanism design}
\label{sec:economics}

Privacy is a complex social phenomenon and the
importance of nuanced social theories like
contextual integrity cannot be overstated.
However, it is also a fact that technical
infrastructure that spans social contexts
is most often developed by private companies that are more
responsive to economic principles than social norms.
Having motivated the inquiry by reflecting on
philosophical and legal theories of privacy,
I will now turn to the economics of privacy,
as economics are at the core of the social and
legal questions that have concerned other scholars.
Though narrower in scope, the field of economics
has provided a rich
literature on privacy that lends precision to
claims about how interests
or incentives shape outcomes.

Modern economics of privacy concerns itself mainly with
concerns about the economics of personal information
as it is used by businesses employing
information technology.
Specially, it most often addresses what Acquisti,
 Taylor, and Wagman \cite{acquisti2016economics} 
call \emph{tangible} impacts of privacy, those impacts that
have objectively measurable and modelable costs and
benefits and effects on market structure.
While others acknowledge the possible importance
of \emph{intangible} impacts, such as a psychological
concern about how ones personal information may be
used (which may be modeled as a subjective preference
for privacy \cite{calo2011boundaries} 
\cite{cofone2017dynamic}) and other more global
social effects, we will limit the discussion in this
paper to tangible impact.

Even so narrowly scoped, there are many different
economic contexts in which the presence or absence 
of personal information is critically relevant. 
There are so many different contexts, each represented
in their own sophisticated scholarly literatures,
some \cite{acquisti2016economics} argue that a comprehensive
economics of privacy cannot be achieved.
Essentially, this is an argument that the economics
of privacy should be contextualized, echoing
the contextualized account of privacy outlined
in Section \ref{sec:limitations}.
But what if we want to understand the economic impact of
information flowing \emph{between economic contexts}?
In order to accomplish this, we need an economic framework
that can model many different kinds of economic contexts,
as well as a the ways in which they may interact.

More concretely, economics has so far failed to come up
with a theory explaining why people \emph{buy and sell data},
and how they price it.
Such a question is critical for explaining the way personal
information transfers from business to business in the case
of, say, online behavioral advertising.
I posit that this is in part because of the slippery
ontological properties of data: it is not a thing that
one can hold as property and its main economic value is
informing the actions of other agents (such as pricing
decisions).
In other words, the value of data is often the value
of the strategic advantage provided by the data.
This may help explain why often companies are often
more interested in buying and selling
flows of data, such as those provided by a web-based
Application Programming Interface (API), than any particular
piece of data.

One tool in the economics toolkit for understanding
policy decisions is mechanism design. \cite{hurwicz2006designing}
\cite{nisan2007introduction}
Mechanism design is an ``inverted game theory'',
wherein the designer defines a range of possible
economic games and chooses the structure of the game
that maximizes some predetermined goal or objective
function.
The objective is a function of the outcome of the
game assuming the players are operating according
to strategies that are rationally optimized for their
self interest, such as the strategies of a Nash Equilibrium.
This in turn provides insight about what kind of rules
can be imposed on an economic transaction such that socially
prefered outcomes result, even when the economic actors
are self-interested.

In this section, I will develop a framework for mechanism
design of economic situations involving information flows.
This framework will extend the Multi-Agent Influence Diagram
(MAID) framework \cite[koller2003multi], which is a
game-theoretic extension of Bayesian Networks.
This framework, which was briefly introduced in Chapter 2,
models information flow in a social context as information
is understood by engineers and economists.
For regulatory regimes to be most effective, they must
be reducible, in the scientific sense, to something like
this model. In Section ???, I will reflect back on whether
and how this model can reflect the restrictions of information
law.


\subsection{Formalizing information flow mechanisms}
\label{sec:formalizing}

We have motivated the need for a general framework
for mechanism design for economics contexts involving
(personal) information flow.
In this section, I will specify that framework.
Summarizing prior work (see \emph{Dissertation Chapter 2},
\cite{benthall2017origin}), I synthesis a formal representation
of information flow from Nissenbaum,
Dretske \cite{dretske1981knowledge},
Shannon,
and Pearl \cite{pearl1988probabilistic}.
In this representation, information flow is a causal flow
that carries nomic associations, which can be represented
precisely using Bayesian networks.
I then propose the use of Multi-Agent Influence Diagrams,
a game theoretic extension to Bayesian networks, as
a framework for mechanism design in privacy economics.
\cite{koller2003multi}

\subsection{Formal theory of information flow}

An upshot of CI is that it identifies privacy as a 
property of information flows, which when unpacked proves
to be a more substantive claim than it may first appear.
When we speak about "consumer information" or 
"personal information", we are faced with the ambiguity
of the meaning of the word "information", which can mean
alternatively either a medium of representation (such as
paper or electronic records, "data") or a mathematical
relationship between events or objects such that one
is sufficient for inferences about the other
\cite{nunberg1996farewell}.

\cite{benthall2017origin} provides an mathematical
analysis of the concept of \emph{information flow}
on robust foundations: Dretske's philosophical theory
of information flow and Pearl's account of statistical
causation.

Dretske's \cite{dretske1981knowledge} formulation
that a message carries information about something it represents
if and only if it messages of its kind carry a regular or ``nomic''
relationship with what is represented.
Dretske develops this philosophical account of information flow
to be consistent with classical information theory
\cite{shannon1948mathematical}, in which an information channel
establishes a correspondence between the probability distributions
of two random events.
The emphasis on the regularity of the probabilistic relationship
suggests the need for an account of how messages can flow
in a structured way.

Just such a theory of structured probabilistic relationships
can be found in Pearl's theory of statistical probability and causation 
\cite{pearl1988probabilistic}, and more generally theory
around Bayesian networks.
Bayesian networks provide a formulation of precisely how
causally linked events can be correlated without being
directly caused by each other. For example, two events that
share a common cause can be correlated.
This means that the nomic associations of a message depend
not just on who sent the message but how the message
is situated in a larger context of messages.

Information flow therefore decomposes into two related parts,
\emph{causal flow} of events and their relationship to each
other, and \emph{nomic associations} between events.
Both of these properties of information flow can be
deduced from a model of information's context as a
Bayesian network.

A fully specified Bayesian network, complete with
conditional probability distributions at every
node, will determine not just the existence of
a nomic assocation (or, equivalently, a conditional
independence), but also the strength fo the association.
Many measures of associative strength are possible,
but one useful measure that is very well understood is
Shannon's \emph{mutual information}:

\begin{dfn}[Mutual information]
  The mutual information of two discrete random variables
  $X$ and $Y$ is

  $$I(X,Y) = \sum_{x \in X} \sum_{y \in Y} p(x,y) log \frac{p(x,y)}{p(x)p*y)}$$
  In particular, $I(X,Y) = 0 \iff X \independent Y$.
\end{dfn}

See Appendix \ref{appendix:information-theory-theorems} for
theorems concerning the ways bounds on mutual information
between variables can be read off of Bayesian networks.

\subsection{MAIDs and Mechanism Design}

Introduced briefly in Chapter 2, the Multi-Agent Influence Diagram
(MAID) framework developed by \cite{koller2003multi} provides
a game-theoretic extension to Bayesian networks.
As a formalism, it is well suited for modeling how
information flows, which we have detailed as causal
flows with nomic associations, play a role in strategic
games.
A full account of the formalism is in the
Appendix \ref{appendix:maid}.

MAIDs extend Bayesian networks with two new node types:
decision variables, and utility variables.
Chance variables are much like the nodes in a Bayesian
network: a CPD is defined for each chance variable
that conditions on its parent nodes.

Utility variables are much like chance variables,
but they are each assigned to an agent $a \in \mc{A}$
and they may not have children.
The utility for each player in the game defined by
the MAID is the sum of the values of the utility
nodes assigned to them.

Decision variables are assigned to an agent $a \in \mc{A}$.
Their CPD functions are not defined as part of the MAID.
Rather, the choice of CPD function for each decision variable
is a strategic choice of the agent. The strategy profile $\sigma_a$
for each agent is their assignment of a CPD to each decision variable.
Taken to together, the strategy $\sigma$ of all the players
induces a MAID into a Bayesian network, from which the
expected utilitites of all players may be computed.

In this work we have extended the MAID framework in a few
respects.

First, we have introduced the mechanic of an \emph{optional edge},
represented in our diagrams as a dotted edge.

\begin{center}
\begin{tikzcd}
  A \arrow[r, dotted] & B \\
\end{tikzcd}
\end{center}

A dotted edge represents a potential information flow
whose value is the focus of the study.
An optional edge means a diagram represents two
distinct MAIDs, one with the edge ``open'' or present
in the graph, and one with the edge ``closed''.
We will look at the outcomes of the open and closed
cases and evaluate them
according to values like efficiency and equity.

Intuitively, there's a difference between information that
becomes suddenly available, as in a data breach, and
well-establish information flows to which everyone is
accustomed, such as security cameras in malls.
In both cases the information flow will have an effect on
outcomes, but the cases are subtly different.
I try to capture this difference by distinguishing between the
tactical and strategic
value of information (this is formalized in Appendix
\ref{sec:value-of-information}).
The tactical value of information is its value to an agent
assuming all other agent's strategies remain fixed.
The strategic value of information is the difference
in an agent's utilities in the open and closed cases,
consider a strategic equilibrium of all players in each case.

In the cases discussed in this chapter, I will consider
the strategic value of information flow except when specifically
stated otherwise.

\section{Single Context Economic models}
\label{sec:single-context}

In this section, I will demonstrate ...
... using simple economic models of well-known
phenomena in privacy economics.

The innovation in these models is that they
use MAIDs to model the strategic decisions,
and that this makes explicit the relationship
between information flow and contextual outcomes.

\subsection{Agent quality uncertainty}
\label{sec:agent-quality}

One of the first contexts studied under the
term ``privacy economics'' was labor
markets \cite{posner1981economics}.
In labor, insurance, and credit markets,
a firm must evaluate natural persons
for their individual capacities (to perform a certain kind
of work, to avoid risk, or to repay a loan) and decide
whether to invest resources in them.
The firm generally benefits from having more information
about the persons under consideration.
The effect of privacy, or lack of it, is uneven across
the population being considered by the firm.
Paradigmatically, more suitably employees are benefited
if their suitability is known to potential employers,
while conversely less suitable employees are harmed
by the same.
Analogous results hold for credit and insurance.

We can model this interaction with the following graph:

\begin{center}
\begin{tikzcd}
  & V \arrow[d, dotted] \arrow[ddr, bend left = 20] & \\
  & \tilde{B_p} \arrow[dr] \arrow[dl] &\\
  \breve{U_a} & & \breve{U_p}\\
\end{tikzcd}
\end{center}

In this model, $V$ represents the value to a principal
of a service or contract with an agent.
For simplicity, in the model $V$ is normalized
with a predetermined price, so the value of $V$
may be negative.
At $\tilde{B_p}$, the principal decides whether or not to buy
the contract; $dom(\tilde{B_p}) = \{0,1\}$.

The utility awarded to the principal is the normalized
value of the contract if the principal buys and zero
otherwise.

$$U_p = \begin{cases}
               V & \text{if } \tilde{B_p} = 1 \\
               0, & \text{otherwise}\\
\end{cases} = \tilde{B_p} V$$

The utility for the agent is, for simplicity, 
a fixed amount (for example $1$) if the principal buys the contract,
and zero otherwise; so $U_a = \tilde{B_p}$.

This model affords some simplifications through backwards 
induction.
The optimal strategy for the principal is 
to buy the contract if the expected value of it is positive.
iIf the dotted edge is open, then the principal is able to use
the know $V$ to make this decision.

If the dotted edge is closed, then the optimal
decision $\hat{B_p}$ depends only on
the distribution of $V$.

\begin{equation}
  \begin{split}
    \hat{B_p} & = \argmax_{b_p \in {0,1}} \E(U_p) \\
      & = \argmax_{b_p \in {0,1}} b_p \E(V) = \begin{cases}
      1 & \text{if } \E(V) \geq 0 \\
      0, & \text{otherwise}\\
    \end{cases}
  \end{split}
\end{equation}


If the dotted edge is open, then the decision to buy
the contract will be better informed.

\begin{equation}
  \begin{split}
    \hat{B_p \vert V = v} & = \begin{cases}
      1 & \text{if } v \geq 0 \\
      0, & \text{otherwise}
    \end{cases} \\
    & = [v \geq 0]
  \end{split}
\end{equation}

\begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
  $\E(\cdot)$ & Open & Closed \\
 \hline
 $U_p$ & $\E(V \vert V \geq 0) P(V \geq 0)$ & $[\E(V) \geq 0] V_E$  \\ 
 $U_a$ & $P(V \geq 0)$ & $[\E(V) \geq 0]$  \\
 $U_a \vert V \geq 0$ & $1$ & $[\E(V) \geq 0]$  \\
 $U_a \vert V < 0$ & $0$ & $[\E(V) \geq 0]$  \\
 \hline
\end{tabular}
\end{center}
where $V_E = \E(V)$

\begin{exm}
  Let $V$ range over $\{-1,1\}$ with even odds.
    $V_E = 0$, $[\E(V) \geq 0] = 1$.
    So the utility to the agent in the closed case, whatever their quality,
    is $1$, and the expected utility to the principal is $0$.
    In the open case, the principal's utility is
    $\E(V \vert V \geq 0) P(V \geq 0) = 1 * (.5) = .5$.
    The high-quality agents get utility $1$, and the low
    quality agent gets utility $0$.
\end{exm}

From this example, we can see that principals and agents
who can offer more valuable contracts benefit from more
openness, while agents with low-value contracts suffer.


\subsubsection{Values}

Early work on privacy economics reasoned that
flow of personal information in labor markets
leads to greater economic efficiency. \cite{posner1981economics}
The MAID model in Section \ref{sec:agent-quality}
does reflect this reasoning.
More flow of personal information (the open condition)
brings greater utility to the principal
on average, and this is a form of market surplus.

It must also be noted that personal information flow
has an unequal effect on the contract agents.
Less valuable contract agents are negatively impacted
by the flow of their personal information.
In this narrowly considered economic context there 
is a global tradeoff between economic productivity,
lubricated by flows of personal information, and
equality.

This model is general enough to extend to cases where
agents are not natural persons but rather firms.
Indeed, the situation may be flipped: a single
natural person may have to choose among many firms
in order to, for example, contract an improvement to
their home.
The model therefore generalizes from cases of privacy
economics to other cases where there is quality uncertainty
and the buyer has market power.
A question for policy designers is whether individual
privacy is any more worthy of protection than
information about firms to those who would
hire their services, and why.

One reason to be wary of a hiring or other contract
choice depending on personal information is indirect
discrimination.
If contract value is negatively correlated with membership
in a protected class of persons, choosing contracts solely
on the basis of value might compound an injustice, which
Hellman argues there is a duty to avoid doing.
\cite{hellman2017indirect}
Modeling historical injustice with MAIDs is a problem
left for future work.

\subsection{Price differentiation}
\label{sec:price-differentiation}

It is well known that personal information
is used by on-line retailers for price differentiation 
\cite{shapiro1998information, varian2001economics}.
According the classic economic theory,
when a firm charges all consumers at the same price
it leaves
some unserved by the market (because the price
exceeds their demand) and some accruing a
consumer surplus (because their demand exceeds
the price).
With differentiated prices, a firm can charge
individual or groups of consumers
closer to their reservation prices. 
This reduces deadweight loss by
charging consumers with very low willingness to pay
a price they can afford, while transforming consumer
surplus formerly accrued by those with high reservation
price to the firm as producer surplus.

We can model this context graphically like so:

\begin{center}
\begin{tikzcd}
  & V \arrow[d, dotted] \arrow[dd, bend left = 40] \arrow[dddl, bend right = 20] & \\
  & \tilde{R}_f \arrow[d] \arrow[ddl, bend right = 20] \arrow[ddr, bend left = 20] & \\
  & \tilde{B_c} \arrow[dr] \arrow[dl] &\\
  \breve{U_c} & & \breve{U_f}\\
\end{tikzcd}
\end{center}

In this model, $V$ represents a consumer's demand for a product.
$\tilde{R}_F$ is the price offered by the firm for the product
(costs normalized out) based on the available information $S$.
At $\tilde{B_c}$, the consumer decides whether or not to buy
the product; $dom(\tilde{B_c}) = \{0,1\}$.

The firm's utility is the offered price of the product if
it is bought and zero otherwise; $U_f = B_c R_p$.

The consumer's utility is their demand minus the price if
they buy the product and zero otherwise; $U_c = B_c (V - R_p)$.

Once again, we can consider two cases.
In the ``closed'' case,
the firm does not know the demand of the individual
consumer.
They only know the general distribution.
The consumer will buy the product if and only if
the price is lower than their demand or reservation price;
$\hat{B} = [V > R]$.
The firm must choose $\hat{R}$ that maximizes their expected
revenue:

$$\hat{R} = \argmax_{r \in \R} \E(r [V > r])$$

If $V \geq \hat{R}$, then the consumer will find the
price agreeable and purchase the good, accruing $V - \hat{R}$
utility.
Otherwise, they will not purchase the good.

In the ``open'' case, the producer knows the reservation price
$V = v$ when deciding their price $\hat{R}$.

$$\hat{R} = \argmax_{r \in \R} r [v > r]) = v - \epsilon$$

This value approaches $v$ from below, and for simplicity of
presentation we will use $\epsilon$ to represent a vanishingly
small value.

\begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
  $\E(\cdot)$ & Open & Closed  \\
 \hline
 $U_f$ & $V_E - \epsilon$ & $\hat{R} P(V \geq \hat{R})$ \\ 
 $U_c$ & $\epsilon$ & $(V - \hat{R}) [V \geq \hat{R}]$  \\
 $U_c \vert V \geq V_E$ & $\epsilon$ & $V - \hat{R}$  \\
 $U_c \vert V < V_E$ & $\epsilon$ & 0  \\
 \hline
\end{tabular}
\end{center}

where $V_E = \E(V)$

\begin{exm}
  Let $V$ be a uniform distribution ranging $[0,1]$.
  
  In the closed condition, $U_f = r (1 - r) = r - r^2$,
  implying the $\hat{R} = .5$ and $U_f = .25$.
  $\E(U_c) = .125$.

  In the open condition, $\hat{R} = V - \epsilon$
  and $\E(U_f) = .5 - \epsilon$.
  Consumer utility is $\epsilon$.
\end{exm}

In this price differentiation case, the strategic
value of information to the producer is positive.
The strategic value of the information to the consumer
depends on the consumers' reservation price: it may
be negative, or it may be very slightly positive.
In general, allowing information flow for price
differentiation is better for producers than for
consumers.

\subsubsection{Values}

This model shows the tradeoffs of allowing information
flow in the economic context of price differentiation.
The outcomes for different agents can be inferred from
the model.
It's clear that information flow for the purpose of
price differentiation primarily serves the firm
selling a good or service.
Arguably, this is valuable because it allows firms
to recoup fixed costs for product development with
greater sales.

However, this model shows that price differentiation
is on the whole bad for consumers.
While it's true that consumers with low willingness
to pay have access to the good with price differentiation,
they are charged a price that makes them almost
indifferent to the transaction.
Meanwhile, consumer surplus has drained from those
who valued to the good highly.

This is a case where the purpose of a market context
may be hotly contested by different actors within it.
If the contextual purpose of the market
transaction is to satisfy as much consumer demand as
possible while rewarding productive suppliers,
then allowing information flow for price differention
is wise policy.
But this may be contested by consumer advocates who
would argue that consumer satisfaction is more important
than economic growth.
This context is so raw with economic intent it may be
that not societal consensus is possible.

\subsection{Expertise}
\label{sec:expertise}

Doctors, lawyer, and financial services professionals
all have something in common.
Their clients consult them for their expertise.
In the schematic interaction we'll consider in this
section, we'll consider the case where these clients
must divulge personal information to an expert in
order to get a personalized recommendation or response.

In many of these domains, there are already strong data
protection laws in place in the United States. 
HIPAA in health care,
GLBA in personal finance, and FERPA in education all
place restrictions on institution's ability to disclose personal
information that's collected as a part of that instition's
normal professional service. (See Section \ref{sec:confidentiality}.)
Notably, there is no similar data protection law for search
engine queries, which may also be considered a kind of expert
recommendation service.

The MAID modeling tool we have been using can capture
the difference in knowledge between the client and
the expert and the consequences that has for the service
market.

\begin{center}
  \begin{tikzcd}
    & W \arrow[ddl, bend right = 40] \arrow[ddr, bend left = 40]& \\
    & C \arrow[dl] \arrow[dd] \arrow[dr, bend left = 20, dotted]& \\
    V \arrow[dd] \arrow[ddr, bend right = 20] &  & \tilde{R}_e \arrow[dl] \\
    & \tilde{A}_c \arrow[dl] \arrow[d] &\\
     \breve{U_e} & \breve{U_c} &\\
  \end{tikzcd}
\end{center}

In this model, $W$ are facts about the world that
determines the relationship between personal qualities
of clients and the best course of action taken by them.
For example, this may be thought of as parameters in
a function from symptoms of illness to appropriate prescribed
remedies.
Its domain is some flavor of $n$-by-$m$ matrices, where
$n$ is the number of personal characteristics or types in the model,
$m$ is the number of actions available to the client,
and $W_{i,j}$ is the reward to a client with of type $i$
of action $j$.

The variable $C$ encodes those personal qualities known to
and communicable by the client.
The domain of this variable is an integer from 1 to $n$.

The variable $V$ encodes the value of a particular to the client
of a variety of courses of action that they might take.
It depends on $W$ and $C$, and in the simple version of the
model considered here is a deterministic function: $V$
is the row of $W$ indexed by $C$.

$\tilde{R}_e$ is the strategically determined decision of
the expert to recommend a course of action based on their
knowledge of $W$ and optionally $C$. Its domain is an
integer from 1 to $m$.
$\tilde{A}_c$ is the decision of which action the client takes.
It also has domain from 1 to $m$.
$U_c$ and $U_e$ are the utilities awarded to the client and expert,
respectively, which take their value from the vector $V$ indexed
by the value of $\hat{A}_c$.

Perhaps idealistically, we have modeled the utility
of the expert as depending only on the utility of the
client.
We imagine that the client pays for the expertise
up front, that this is normalized into the value
of the action taken $V$, and that the expert
benefits from the positive recommendations of
satisfied clients.
Future work and other models may explore other
possible configurations of incentives.
For an action taken $a \in A$, we will
specify that $U_c = V(a)$.

We will once again consider two cases.
In the closed case, there is no edge from
$C$ to $\tilde{R}_e$.
In this case, the expert still has specialized knowledge
(the value of $W$), but no personal information about the
client with which to tailor their recommendation.
Their best recommendation is the action that would
benefit a random client the most in expectation.

$$\hat{R}_{closed} = \argmax_{a \in A} \E(V(a) \vert W)$$

The client, on the other hand, has access to information
about their symptoms $C$ but not the expert knowledge $W$.
By the assumption of the model, the client does have access
to the expert's recommendation, $\hat{R}_{closed}$.
So their choice of action is:

$$\hat{A}_{closed} = \argmax_{a \in A} \E(V(a) \vert C, \hat{R}_{closed})$$

In the alternative ``open'' condition, there is an edge between
$S$ and $\tilde{R}$.

$$\hat{R}_{open} = \argmax_{a \in A} \E(V(a) \vert W,C)$$

$$\hat{A}_{open} = \argmax_{a \in A} \E(V(a) \vert C, \hat{R}_{open})$$

The specific utility outcomes depend heavily on the parameters of
the model.
We can make a few general observations about bounds.
If the model is such that individual symptoms carry no
information about the value of actions taken even with expert
knowledge taken into account ($V \independent C \vert W$,
$V \independent C$),
then the welfare outcomes in the closed case and the open case will
be the same.

If the expert knowledge $W$ has information
about the action values given the symptoms ($I(W;V \vert C) > 0$),
then the expert recommendation $\hat{R}_{open}$ will generally be better
in expectation than $\hat{A}_{closed}$ and indeed
$\hat{A}_{open} = \hat{R}_{open}$.

Note that there is an interaction between the strategies of the
expert and the client.
The optimality of the expert's strategy at $\tilde{R}_e$ depends
on how its signal will be ``interpreted'' at $\tilde{A}_c$.
Interpreting $\tilde{R}_e$ as a recommendation implies some
correspondence between the value taken at that variable and
the values of actions according to $V$.
But in some cases an alternative encoding of the information
in $W$ (and $C$) may be more efficient.

An example of the instantiated model will illustrate these points.

\begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
  $\E(\cdot)$ & Open  & Closed \\
 \hline
 $U_e$ & $\E(V(\hat{A}_{open}))$ & $\E(V(\hat{A}_{closed}))$ \\ 
 $U_c$ & $\E(V(\hat{A}_{open}))$ & $\E(V(\hat{A}_{closed}))$  \\
 \hline
\end{tabular}
\end{center}

\begin{exm}
  Let $n$ and $m$ both equal 2.
  Let the domain of $W$ be binary 2-by-2 matrices with
  the restriction that each row contains one 0 and one 1.
  Let the distribution of $W$ be uniform over the four
  possible matrices in its domain.

  In the closed case, $\tilde{R}_e$ does not depend on $C$.
  $\tilde{R}_e$ is therefore a strategically chosen encoding
  of only the information in $W$.
  Notably, whereas the random variable has 2 bits of information,
  $\tilde{R}_e$ ranges over 0 and 1 and can carry at most 1 bit of
  information.

  One such encoding, communicating one bit from $W$, is:

  $$\hat{R}_{closed} \vert (W = w) = \begin{cases}
    1 & \text{if } w_{0,1} = 1 \\
    0, & \text{otherwise}\\
  \end{cases}$$

  At $\tilde{A}_c$, the client knows both $C$ and $\tilde{R}_e$
  and must choose an action that optimizes their expected utility. 
  At this node the client knows if they are of type 0 or 1.
  If they are of type 0, they know the recommendation applies 
  to them, with certainty of a reward of 1 if they take the suggested action. 

  $$\hat{A}_c \vert (C = 0) = \hat{R}_c$$

  But if the client knows they are of type 1 (probability $.5$),
  then the recommendation
  does not encode information about the value of their action.
  Whatever action they take has an even chance of having utilty of 0 or 1.
  Expected utility in the closed case is $.5 * 1 + .5 * .5 = .75$.
  
  In the open case, the expert's recommendation $\tilde{R}_e$
  depends on both $W$ and $C$.
  From this information, the expert can deduce the one bit of
  information relevant to the client's decision, which is
  $V$.

  $$\hat{R}_{open} \vert (W = w, C = c) = \begin{cases}
    1 & \text{if } w_{c,1} = 1 \\
    0, & \text{otherwise}\\
  \end{cases}$$

  In this case, when $\hat{A} = \hat{R}_{open}$,
  the value of the action is guaranteed to be $1$,
  which implies that the expected utility in the
  open case is $1$.

  The strategic value of the information flow from
  $C$ to $R$ is the difference in expected utilities
  in the two cases, which in this example is $1 - .75 = .25$.
\end{exm}

In this example, the expert chooses a strategic at
$\tilde{R}$ that maximizes the flow of information,
in the Shannon sense of the term,
to $\tilde{A}$ about another variable of interest,
$V$. Or, formally:

$$\hat{R} = \arg \max_{R} I(R;V)$$

In the closed case, the limited domain of $\tilde{R}$,
which permits the flow of at most one bit of information,
restricts the expert's ability to provide an adequate
recommendation to the client.
If the number of bits in $R$ was greater than or
equal to the number of bits in $W$, the expert would
be able to communicate the entirety of their expertise
to the client, who could then make a perfect judgment
of action taking $C$ into account.

This information theoretic lens provides a new view
into personalized expert advice.
Personalization is useful to the client only because
the client lacks expertise, but this lack of expertise
is due in part because the expert cannot communicate
all the information they know to the client.
Personalization allows the expert to provide the highest
value information through the narrow bandwidth of
communication.
The constraints on information flow are due mathematically
to the Data Processing Inequality and its consequences
for Bayesian networks, which are discussed at length in
\ref{appendix:information-theory-theorems}.

\subsubsection{Values}

This model of expert services has been simplified
to exclude cases of expert conflicts of interest
that might engage societal values in mechanism
design.
We accomplished this simplification by directly
aligning client and expert incentives.
Despite this simplification, the model
shows some of the difficulty in modeling
the welfare outcomes of expert services.
The principle difficulty is that the outcomes
depend on general facts and the quality of
expertise in a particular domain.
Because it is hard to encode an actual field
of expertise into a simple model we can prove only
very general properties of
such a field.

Despite these difficulties, this simple model
shows that when expert and client incentives
are aligned, greater flow of information
from client to expert enables better outcomes
for both parties.
In a later section, we will elaborate
on this model by introducing the possibility
of a breach of confidentiality.

\section{Cross-context information flow and secondary use of personal data}
\label{sec:cross-context}

In the above models, we have shown how in
a variety of economic contexts the flow of information
can have tangible effects on welfare outcomes.
What these models have in common is that they show
that the relevance of information on outcomes depends
on the process by which it is generated and how
elements of that process affect outcomes.
While we have provided narrative cover stories for
each example where we have described the information
flows in terms of particular types of documents or events
(job applications, symptoms, etc.), what really gives
information its semantics are its associational
relationships with other variables.
These are given by the conditional probability
distribution governing the model.

A reason for modeling games with information flow in
this way is to begin to model the challenges of modeling
the economic impact of the \emph{secondary use} of data.
It is the cases where data collected for one purpose or context
is used in another that are often presented as alarming.

\subsection{Cooperating Firms: Price differentiation and agent quality}
\label{sec:cooperating-firms}

Consider the following model, constructed as a combination
of the agent quality uncertainty and price differentiation
models.
Here $c$ is a natural person who is \emph{both} potentially
a consumer of firm $f$'s products and potentially involved
in a contract with principal $p$.
The value of this person's contract $V^1$ and their
willingness to pay for the product $V^2$ both depend on
a prior variable $W$ that encapsulates many factors about
the background of the person.

\begin{center}
  \begin{tikzcd}
    & & W \arrow[dl] \arrow[dr] & & \\
  & V^1 \arrow[d] \arrow[dddl, bend right = 20] \arrow[dddl, bend right = 20] \arrow[dd, bend left = 40] & & V^2 \arrow[dddr, bend left = 20]&  \\
  &  \tilde{R}_f \arrow[d] \arrow[drr, dotted] \arrow[ddl, bend right = 20] \arrow[dd, bend left = 40]  &  & & \\
  & \tilde{B_c} \arrow[d] \arrow[dl] &  & \tilde{B_p} \arrow[dr] \arrow[d] &\\
  \breve{U_f} & \breve{U_c^1} & & \breve{U_c^2} & \breve{U_p}\\
\end{tikzcd}
\end{center}

As before, $V^1 \rightarrow \tilde{R}_f$ represents the ability of
the firm to known the customer's demand before choosing their
price.
There is also a principal that decides at $\tilde{B}_p$
whether or not to buy a contract with the customer, who
in this case is also an agent for hire.
In this model, the principal cannot know the value
of the contract $V^2$ directly.
Rather, there is a new edge $\tilde{R}_f \rightarrow \tilde{B}_p$
that represents
the option of the product-selling firm $f$ to share its
pricing information with the contract principal $p$.

Why would two companies ever interact in this way?
If the principal does \emph{not} know the value of
a potential contract $V^1$ directly, then the pricing
information $\hat{R}_f$ potentially contains information
about $V^1$ in a way that the principal $p$ can use
Here, ``contains information about'' can be read to
mean ``has mutual information with'', i.e.
$I(\hat{R}_f, V^1) \geq 0$.
This information may be valuable for the principal
by allowing them to avoid bad contracts.

Since the principal and the producing firm's utility's
do not interact directly in any other way, we can
imagine that the principal would be willing to
purchase the pricing data from the producing firm
for the \emph{value of the data to the principal}.
Though this data relates directly to
a natural person, it is not data collected from that
person; it is data derived from the producing firm's
pricing algorithm.
Nevertheless, sharing this data has a function analogous
to sharing personal data that could be used in a hiring decision
or in offering a loan.

In this situation, the firm's incentives are the same
as in the simple price differention
case in Section \ref{sec:price-differentiation}.
By assumption, the firm knows the customer's demand
$V^1$, and therefore prices at $\hat{R} = V^1 - \epsilon$.

\begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
  $\E(\cdot)$ & Open & Closed  \\
 \hline
 $U_f$ & $V^1_E - \epsilon$ & $V^1_E - \epsilon$ \\
 $U^1_c$ & $\epsilon$ & $\epsilon$ \\
 $U_p$ & $\E(V^2 \vert V^2 \geq 0) P(V^2 \geq 0 \vert \hat{R})$ & $[\E(V^2) \geq 0] V^2_E$  \\
 $U_c^2$ & $P(V^2 \geq 0)$ & $[\E(V^2) \geq 0]$  \\
 $U_c^2 \vert V^2 \geq 0$ & $1$ & $[\E(V^2) \geq 0]$  \\
 $U_c^2 \vert V^2 < 0$ & $0$ & $[\E(V^2) \geq 0]$  \\
 \hline
\end{tabular}
\end{center}

where $V^1_E = \E(V^1)$ and $V^2_E = \E(V^2)$.

\begin{exm}
  Let $W$ vary over $\{0,1\}$ with even probability,
  with the value corresponding to one of two socioeconomic
  classes, \emph{low} and \emph{high}.

  In this example, we will assume that higher class people
  have access to better education and wealth, and therefore
  both have higher reservation prices and offer higher value
  contracts to creditors, employers, and insurance providers.

  $$V^1(w) = \begin{cases}
    10 & \text{if } w  = 1 \\
    1, & \text{otherwise}\\
  \end{cases}$$
  
  $$V^2 = \begin{cases}
    1 & \text{if } w  = 1 \\
    -1, & \text{otherwise}\\
  \end{cases}$$

  The firm has access to the reservation price $V^1$
  at $\tilde{R}_f$ and so will maximize their utility
  by pricing at slightly below the customer's willingness
  to pay.

  $$\hat{R}(v) = v - \epsilon$$

  The optional edge being considered in this case runs
  from $\tilde{R}$ to $\tilde{B}$.
  In the closed case, the principal has no information
  about $V^2$ on which to decide except the base rate
  provided by the game structure.
  The expected value to the principal of providing the contract
  is $0$.

  In the open case, $\tilde{B}$ is conditional on $\tilde{R}$.
  Crucially, $V^2$ is conditionally dependent on $\hat{R}$.
  In particular:

  $$P(V^2 = 1 \vert \hat{R} > 1) = 1$$
  $$P(V^2 = 0 \vert \hat{R} \leq 1) = 1$$

  The optimal strategy for the principal is to hire
  the agent when the firm reveals to them that they offered
  a high price for the good, and to reject the agent otherwise.
  The high quality contract is purchase half the time with reward
  $1$ to the principal.
  So the strategic value of the information flow from $\tilde{R}$
  to $\tilde{B}$ to the principal is $.5$.
  The strategic value to the average customer/agent of this information flow
  is negative, as it results in many customer/agents not getting hired.
\end{exm}

In this simple example, in strategic equilibrium the firm's offered
price and the customer/agent's contract quality
are highly correlated.
This means that a \emph{causal flow} between the firm's price and
the principal's hiring decision carries a \emph{nomic association}
with the contract value.
That association has strategic value for the principal similar to
the value of having the contract value's causally flowing directly
to the hiring decision.

The secondary use of data to determine the social class of
natural persons is not an academic hypothetical.
Facebook has filed a patent to use information about
user's hardware specifications, presumabely collected originally
to optimize service performance, to predict social class, presumably useful
for targeting advertisements \cite{cb_insights_research_2018}.
The cross-context use of personal data for targetted advertising
is arguably the fundamental business proposition of on-line
advertising companies like Facebook and Google.

The strategic value of the information to the principal can
be interpreted as the price at which the principal would
be willing to purchase this information flow from the firm.
This price depends on the causal structure of the environment,
including the distribution of qualities of natural persons.
Even though natural persons are on average worse off as a result
of this information flow, this is not a factor in its
value or price to the principal.
This can be considered a market externality, though
because it involves a new flow of information, it
may also correct a market inefficiency.

\subsubsection{Values}

The outcomes of this game are similar to the outcomes
in the simple principal agent case.
The difference is that the information flow
runs between two cooperating firms.
This models the flow of information from one
economic context (price differentiation on a consumer good)
to another (a principal-agent hiring decision).
Because the two contexts are part of a shared
causal environment, the data from from one context
can carry meaningful information relevant to another.

It's notable that the natural person in this example,
who is both a customer and an agent to be hired,
is (on average) disadvantaged by the hypothetical
transaction taking place between two firms.
This is a market externality, though the
flow of information corrects a market inefficiency
in the second economic context.
There is a tradeoff between market efficiency,
which is good for firms,
and the privacy of natural persons, and especially
the most vulnerable natural persons.

\subsection{Secondary use of queries to experts}

Section \ref{sec:cooperating-firms} detailed the
potential negative impact on vulnerable natural persons from
an information flow that crosses economic contexts.
It is possibly because of the potential negative impact
of secondary uses of information that so many market segments
are protected by sectoral privacy and confidentiality laws.
HIPAA in health care,
GLBA in personal finance, and FERPA in education all
place restrictions on firm's ability to disclose personal
information. (See Section \ref{sec:confidentiality}.)
What these sectors all have in common is that they do not
function without significant disclosures of personal
information to firms because the provide personalized
service unavailable to the consumer.
The expertise model in Section \ref{sec:expertise}
captures why personal information is necessary for
the functioning of these services in fundamental
mathematical and economic terms: personalization
allows expert service providers to deliver more
value to clients given a tight information bottleneck
relative to the body of knowledge of the expert.

Section \ref{sec:cooperating-firms} provides a template
for understanding why disclosure of sensitive information
from the context of expert services into other domains
could have negative externalities for natural persons.
Indeed, information we provide our doctors, lawyers,
financial advisors, and search engines is sensitive
precisely because this information is potentially
impactful in other contexts in ways that are surprising
and/or unwelcome.

Whereas the firms in \ref{sec:cooperating-firms} both benefit
from the sale of personal information, the sale of personal
information from expert services may have secondary effects
that negatively impact experts.
If clients are aware of a harmful information flow, they
may be reluctant to engage the expert.
In the the terminology introduced earlier, an expert
may get tactical value from selling personal information
of its clients, but if clients can adjust their behavior
according to new expectations, the strategic value of
this information flow to experts will be negative.

\section{Discussion}
\label{sec:discussion}

This chapter has developed a framework for modeling
economic games with information flow.
This framework expands MAIDs with optional edges,
which results in a system for modeling mechanism
design with Bayesian Networks.
This framework can model well understood cases of
privacy economics (principal agent, price differentiation)
as well as the lesser understood case of expert services.
The framework makes it clear how the fundamental limits
of information theory, as well as the nature of information
flow as causal flow with nomic associations,
relates to the economics of information
services.
The models show that sometimes personal information flow
improves market efficiency at the expense of consumers
and riskier agents.
These models allow for a direct comparision between social
values and the outcomes of policies allowing or disallowing
personal information flows. (Section \ref{sec:single-context}.)

This framework can also model cases where information
flows between economic contexts
(Section \ref{sec:cross-context}.)
In particular, secondary use of personal information can
play an economic role similar to primary use of personal
information if and when the processes that generate
the data result in reliable and useful statistical correlations.
These correlations can occur when society is stratified into
socioeconomic classes, as they are in reality.

Central to this modeling system is a conceptual shift in
how to understand the role of information flow in economics.
In a framework like Contextual Integrity, information flow
gets its meaning from its social context, or the way
the information plays a role in an abstractly and normatively
understood social sphere.
This captures social expectations well, but not the reality
of information flow when businesses develop infrastructure
technologies that span social contexts.
For this, we need a model of information flow that is more
realistic.
We accomplish this by modeling information flows as situated
within larger causal structures.
These causal structures give each individual flow its
nomic associations, which are what make the information
strategically useful.

The model makes clear that the strategic choices of agents
in the economy is one of
the elements that determines the causal structure that gives
information its meaning.
This indicates a major source of confusion in economics of information.
Information is not a good that is bought and sold for consumption.
Information is a strategic resource, part of the social and economic fabric.
When information flows are bought and sold, it changes the
strategic landscape of the economy.
Market externalities abound as information flows effect many parties
who are not party to transactions.

Beyond these general conclusions, there are a number
of more specific implications of these models which
indicate directions of future work.

\subsection{Privacy concerns and privacy competence}

A robust empirical result is that there are
different segments of the general population that have different
privacy concerns.
These are often presented as the marginally concerned, pragmatic majority,
and privacy fundamentalists.
\cite{ackerman1999privacy} \cite{berendt2005privacy}
\cite{sheehan2002toward}
This matches expectations from economic model:
some populations are more vulnerable than others to the
negative effects of personal information flow.
Further work is needed to test to what extent
different preferences or concerns about information
flow are determined by the economic situation
of data subjects.
Class differences may have significant effects,
with implications for value-driven policy design.

There is also evidence that consumers are generally not making
privacy decisions in rational and informed
self-interest but, rather,
become much more concerned with their privacy
when told facts
about how personal information is
used \cite{hoofnagle2014alan}.
There is a disconnect between consumer
expectations and fact.
This may be because the most prominent
privacy threats are beyond user comprehension.

Many serious privacy threats, whether they be Big
Data analytics drawing conclusions from
aggregating for an unforeseen business end,
a network of companies engaged in secondary uses of data
shared between them, or an illicit dark web of hackers
and fraudsters, are due to cross-context inforamation
flows in which the data subject plays little active role.
Section \ref{sec:cross-context} shows the mechanics
of how companies can gain strategic advantage by
reusing personal data to the detriment of consumers.
However, if consumer privacy expectations are tied to
the normative expectations in specific social spheres,
perhaps because these expectations are encoded as mental
models or causally structured frames, then consumers
can not be expected to be competent stewards of their
own personal information.
Consumers cannot act strategically in their interest,
individually let alone collectively, unless they
are aware of how their information is being used.

The true mechanics of information flow, represented here
by Bayesian networks, are opaque and largely unknown.
The framework provided here can be extended to take into
account different degrees of knowledge about the causal
structure that gives information flow its meaning.
Further work is needed to understand the implications
of knowledge and information assymetry in data economy
market equilibria.

\subsection{Market failure}

By the preceding argument, consumers are not competent
to make decisions about how to control their personal
information because their privacy expectations are
tied to contexts that are routinely violated in practice.
Potential secondary uses of personal data depend on
associational properties of the data that are beyond
users comprehension.
In the case of large, data-rich firms,
these associational properties are
discovered through aggregation and data mining by the
very firms that attract consumer interaction through
expert services that they offer.
This data is then used in two-sided markets, which
act as intermediaries in many other economic contexts,
further complicating any prediction of the benefits
and harms of disclosure.
Quantitative, let alone qualitative, prediction of
these harms and benefits is beyond what an individal
can accomplish.

In the absence of a more concrete culprit for privacy threats,
security considerations raise a general case for needing
to limit secondary use of personal information.
On the one hand, we can consider security to be another
context where personal information is used, perhaps in a
secondary way.
Uses of personal information which are
harmful to all affected consumers include those that facilitate
security threats like spearphishing (when attackers use
personal information to manipulate a person to reveal 
security-related information or otherwise be a vector
for a further attack) and identity theft.
On the other hand, it is the possibility of harmful secondary
use \emph{across all potential contexts} that makes security of
personal information so important in the first place.
Security in this sense is necessary for an implementation of 
confidentiality.

The conditions appear to be ripe for classic market failure,
or else there would be if there were a market to begin
with.
As has been mentioned, property rights for
personal data are weak if not nonexistant (see Section \ref{sec:law}).
Personal data is not a good being produced by anybody
in the privacy economics ecosystem.
It is rather information in the \emph{strategic} sense of
allowing some market actors to perform more effectively.
There is no sense in which the market of personal information
has the properties that would lead us to believe the
market would allocate resources efficiently.
Perhaps rather than ask if there is a market failure,
we should be asking what is happening, if not a market at all?

As an alternative to regulating personal data as a kind of property,
some have proposed regulating personal data through tort
\cite{posner1981economics, cofone2017dynamic}.
Certainly some meanings of "privacy", such as those that refer
to protection from libel, are enforceable in this way.
To the extent that considering personal data to be a /thing/
is misleading, it may more more
effective to craft data protection regulation through
the framework of dignitary privacy. \cite{post2017data}
However, as we have discussed it seems unlikely that the scope
of consumer harm or benefit can be adequately assessed given the
scale of the empirical problems involved.

A another alternative is strengthened
data protection laws for two-sided markets involving targeting,
such as advertising in social media platforms.
As we have noted, in most expert service sectors, including
health care, finance, education, and so on, there are existing
sectoral data protection laws ensuring confidentiality.
The existence of these laws is an indication that without
them, these expert service markets would implode in market failure.
If protecting confidential information from secondary use
(through austere prohibitions on disclosure and security
investments) is a form of service \emph{quality}, and this quality
is difficult for consumers to assess independently, then
this information assymetry about service quality would result
in a market failure along the lines of Akerlof's market for
"lemons". \cite{akerlof1970market}
Since unregulated two-sided markets are in the senses described
above equivalent to providing unrestricted secondary use to
other firms, perhaps present economic conditions are just such
a market failure.

\subsection{Purposes}

As discussed in Section \ref{sec:GDPR},
the EU's GDPR attempts to limit the kinds of privacy
violations due to secondary use of personal information
through \emph{purpose restrictions},
which place restrictions on the goals for which collected
data may be used.
Personal data may be processed only for purposes to which
the data subjects consent (with some exceptions).
Further data minimization requirements reduce the amount
to which data is unintendedly exposed to other unintended purposes.
As a way of creating agreement between the expectations of data
subjects and the activities of data processors, this can be
seen as a refinement of the notice-and-consent framework.
It may be argued that purposes are easier to understand
than the complexity of legal and technical reality.

The rising importance of purpose binding as a privacy requirement
raises the question of how the purpose of data processing can
be formalized to facilitate privacy engineering.
Tschantz, Datta, and Wing (2012, 2013) do formalize purpose
in order to provide the basis of
automatic enforcement of privacy policies.
In their approach, ``an action is for a purpose if the
action is part of a plan for achieving that purpose.''
They then go on to formalize this in terms of
a Markov Decision Process (MDP), a way of modeling the relationship between actions,
environment, policies, and outcomes that allows for a formal definition of optimal policy.
A promising direction for future work is to formalize
purpose binding in terms of Bayesian causality and incentives,
extending the mechanism design framework introduced in
this chapter.


\end{document}
